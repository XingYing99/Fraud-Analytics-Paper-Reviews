{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('CCF.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(data=df.corr(), cmap=\"seismic\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicollinearity test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return(vif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V20       V21  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ...  0.251412 -0.018307   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.524980  0.247998   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.208038 -0.108300   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ...  0.408542 -0.009431   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  1.475829  0.213454   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.059616  0.214205   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.001396  0.232045   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.127434  0.265245   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.382948  0.261057   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0       0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1      -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2       0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3       0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4       0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n",
       "284803  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n",
       "284804  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n",
       "284805  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n",
       "284806  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n",
       "\n",
       "        Amount  \n",
       "0       149.62  \n",
       "1         2.69  \n",
       "2       378.66  \n",
       "3       123.50  \n",
       "4        69.99  \n",
       "...        ...  \n",
       "284802    0.77  \n",
       "284803   24.79  \n",
       "284804   67.88  \n",
       "284805   10.00  \n",
       "284806  217.00  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Time</td>\n",
       "      <td>2.339084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V1</td>\n",
       "      <td>1.621694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V2</td>\n",
       "      <td>3.869377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V3</td>\n",
       "      <td>1.255585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V4</td>\n",
       "      <td>1.137944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V5</td>\n",
       "      <td>2.753075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V6</td>\n",
       "      <td>1.522122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>V7</td>\n",
       "      <td>2.510165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V8</td>\n",
       "      <td>1.097151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V9</td>\n",
       "      <td>1.018831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>V10</td>\n",
       "      <td>1.115668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V11</td>\n",
       "      <td>1.028861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>V12</td>\n",
       "      <td>1.011961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>V13</td>\n",
       "      <td>1.003434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>V14</td>\n",
       "      <td>1.026832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>V15</td>\n",
       "      <td>1.014135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>V16</td>\n",
       "      <td>1.000371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>V17</td>\n",
       "      <td>1.004772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>V18</td>\n",
       "      <td>1.006568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>V19</td>\n",
       "      <td>1.037809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>V20</td>\n",
       "      <td>2.233934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>V21</td>\n",
       "      <td>1.100720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>V22</td>\n",
       "      <td>1.082384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>V23</td>\n",
       "      <td>1.149268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>V24</td>\n",
       "      <td>1.000659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>V25</td>\n",
       "      <td>1.013388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>V26</td>\n",
       "      <td>1.000487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>V27</td>\n",
       "      <td>1.008979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>V28</td>\n",
       "      <td>1.001425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Amount</td>\n",
       "      <td>11.499791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variables        VIF\n",
       "0       Time   2.339084\n",
       "1         V1   1.621694\n",
       "2         V2   3.869377\n",
       "3         V3   1.255585\n",
       "4         V4   1.137944\n",
       "5         V5   2.753075\n",
       "6         V6   1.522122\n",
       "7         V7   2.510165\n",
       "8         V8   1.097151\n",
       "9         V9   1.018831\n",
       "10       V10   1.115668\n",
       "11       V11   1.028861\n",
       "12       V12   1.011961\n",
       "13       V13   1.003434\n",
       "14       V14   1.026832\n",
       "15       V15   1.014135\n",
       "16       V16   1.000371\n",
       "17       V17   1.004772\n",
       "18       V18   1.006568\n",
       "19       V19   1.037809\n",
       "20       V20   2.233934\n",
       "21       V21   1.100720\n",
       "22       V22   1.082384\n",
       "23       V23   1.149268\n",
       "24       V24   1.000659\n",
       "25       V25   1.013388\n",
       "26       V26   1.000487\n",
       "27       V27   1.008979\n",
       "28       V28   1.001425\n",
       "29    Amount  11.499791"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "calc_vif(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df.Class\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree model building with grid-search to find optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "param = {\n",
    "    'criterion':[\"gini\",\"entropy\"],\n",
    "    'max_depth': np.arange(2,10,2)\n",
    "    \n",
    "}\n",
    "\n",
    "metric = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(eval_score):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifier using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    grid_search = GridSearchCV(clf, param, scoring=metric, refit=eval_score,\n",
    "                           cv=skf,return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # make the predictions\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    print('Best params for {}'.format(eval_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # confusion matrix on the test data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(eval_score))\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recall_score\n",
      "{'criterion': 'entropy', 'max_depth': 4}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for recall_score on the test data:\n",
      "     pred_neg  pred_pos\n",
      "neg     85277        19\n",
      "pos        35       112\n"
     ]
    }
   ],
   "source": [
    "grid_search_clf = grid_search('recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>mean_test_accuracy_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.999</td>\n",
       "      <td>4</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.999</td>\n",
       "      <td>6</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.999</td>\n",
       "      <td>8</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.999</td>\n",
       "      <td>8</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.999</td>\n",
       "      <td>6</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_precision_score  mean_test_recall_score  \\\n",
       "5                      0.855                   0.766   \n",
       "6                      0.888                   0.763   \n",
       "7                      0.858                   0.760   \n",
       "3                      0.893                   0.757   \n",
       "2                      0.909                   0.754   \n",
       "0                      0.798                   0.730   \n",
       "\n",
       "   mean_test_accuracy_score param_max_depth param_criterion  \n",
       "5                     0.999               4         entropy  \n",
       "6                     0.999               6         entropy  \n",
       "7                     0.999               8         entropy  \n",
       "3                     0.999               8            gini  \n",
       "2                     0.999               6            gini  \n",
       "0                     0.999               2            gini  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_search_clf.cv_results_)\n",
    "results = results.sort_values(by='mean_test_recall_score', ascending=False)\n",
    "results[['mean_test_precision_score', 'mean_test_recall_score', 'mean_test_accuracy_score', 'param_max_depth','param_criterion']].round(3).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering both precision score and recall score, we will choose max_depth=4 and criterion = \"entropy\" as the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def performance(model,X_text,y_test):\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    con=confusion_matrix(y_test, y_pred)\n",
    "    sensitivity=con[1][1]/(con[1][1]+con[1][0])\n",
    "    y_prob=model.predict_proba(X_test)\n",
    "    auprc = metrics.average_precision_score(y_test,y_prob[:,1])\n",
    "\n",
    "    \n",
    "    print(\"auprc:\",auprc)\n",
    "    print(\"sensitivity:\",sensitivity)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auprc: 0.7377026758148634\n",
      "sensitivity: 0.7619047619047619\n",
      "Accuracy: 0.9993679997191109\n",
      "[[85277    19]\n",
      " [   35   112]]\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(max_depth=4, criterion='entropy')\n",
    "decision_tree = decision_tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "performance(decision_tree,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def DecisionTree_Over_sampling(strategy,X,y):\n",
    "        class_1=[]\n",
    "        class_0=[]\n",
    "        accuracy=[]\n",
    "        sensitivity=[]\n",
    "        auprc=[]\n",
    "        for i in strategy:\n",
    "            oversample = RandomOverSampler(sampling_strategy=i)\n",
    "            # fit and apply the transform\n",
    "            X_train_over, y_train_over = oversample.fit_resample(X, y)\n",
    "           \n",
    "            decision_tree = DecisionTreeClassifier(random_state=0, max_depth=4,criterion='entropy')\n",
    "\n",
    "            decision_tree = decision_tree.fit(X_train_over, y_train_over)\n",
    "            y_pred = decision_tree.predict(X_test)\n",
    "            accuracy.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "            # print(confusion_matrix(y_test_over, y_pred))\n",
    "            con=confusion_matrix(y_test, y_pred)\n",
    "            sensitivity.append(con[1][1]/(con[1][1]+con[1][0]))\n",
    "\n",
    "            y_prob=decision_tree.predict_proba(X_test)\n",
    "\n",
    "            auprc.append(metrics.average_precision_score(y_test,y_prob[:,1]))\n",
    "\n",
    "        result=pd.DataFrame({\"strategy\":strategy,\"accuracy\":accuracy,\"sensitivity\":sensitivity,\"auprc\":auprc})\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.999239</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.745059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.995248</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.744366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.995248</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.710136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.995319</td>\n",
       "      <td>0.823129</td>\n",
       "      <td>0.700234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   strategy  accuracy  sensitivity     auprc\n",
       "0      0.10  0.999239     0.802721  0.745059\n",
       "1      0.18  0.995248     0.816327  0.744366\n",
       "2      0.20  0.995248     0.816327  0.710136\n",
       "3      0.35  0.995319     0.823129  0.700234"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy=[0.1,0.18,0.2,0.35]\n",
    "result=DecisionTree_Over_sampling(strategy,X_train,y_train)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy chosen= 0.1\n",
    "#### This decision is made by comparing the overall accuracy , sensitivity and auprc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost-sensitive Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost_sensitive_Decision_Tree(weights,X,y):\n",
    "\n",
    "        accuracy=[]\n",
    "        sensitivity=[]\n",
    "        auprc=[]\n",
    "        for i in weights:\n",
    "            decision_tree = DecisionTreeClassifier(random_state=0,class_weight=i, max_depth=4,criterion='entropy')\n",
    "            decision_tree = decision_tree.fit(X_train, y_train)\n",
    "            y_pred = decision_tree.predict(X_test)\n",
    "            accuracy.append(metrics.accuracy_score(y_test, y_pred))\n",
    "            con=confusion_matrix(y_test, y_pred)\n",
    "            sensitivity.append(con[1][1]/(con[1][1]+con[1][0]))\n",
    "            y_prob=decision_tree.predict_proba(X_test)\n",
    "            auprc.append(metrics.average_precision_score(y_test,y_prob[:,1]))\n",
    "\n",
    "        result=pd.DataFrame({\"weights\":weights,\"accuracy\":accuracy,\"sensitivity\":sensitivity,\"auprc\":auprc})\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weights</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "      <td>0.999450</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.735741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "      <td>0.999450</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.735741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{0: 1, 1: 5}</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.782313</td>\n",
       "      <td>0.730145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "      <td>0.999286</td>\n",
       "      <td>0.782313</td>\n",
       "      <td>0.726214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{0: 1, 1: 15}</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.752306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{0: 1, 1: 30}</td>\n",
       "      <td>0.999251</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.751395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{0: 1, 1: 577}</td>\n",
       "      <td>0.987032</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.703737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          weights  accuracy  sensitivity     auprc\n",
       "0    {0: 1, 1: 2}  0.999450     0.795918  0.735741\n",
       "1    {0: 1, 1: 3}  0.999450     0.795918  0.735741\n",
       "2    {0: 1, 1: 5}  0.999333     0.782313  0.730145\n",
       "3   {0: 1, 1: 10}  0.999286     0.782313  0.726214\n",
       "4   {0: 1, 1: 15}  0.999274     0.816327  0.752306\n",
       "5   {0: 1, 1: 30}  0.999251     0.809524  0.751395\n",
       "6  {0: 1, 1: 577}  0.987032     0.857143  0.703737"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights =[{0:1, 1:2},{0:1, 1:3},{0:1, 1:5}, {0:1, 1:10},{0:1, 1:15},{0:1, 1:30},{0:1, 1:577}]\n",
    "result=Cost_sensitive_Decision_Tree(weights,X_train,y_train)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight chosen:{1:15}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param = {'C': [0.1, 1, 10],\n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "metric = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    " \n",
    "\n",
    "SVM = SVC(random_state=0,probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(eval_score):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifier using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    grid_search = GridSearchCV(SVM, param, scoring=metric, refit=eval_score,\n",
    "                           cv=skf,return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # make the predictions\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    print('Best params for {}'.format(eval_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # confusion matrix on the test data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(eval_score))\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recall_score\n",
      "{'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for recall_score on the test data:\n",
      "     pred_neg  pred_pos\n",
      "neg     85291         5\n",
      "pos        51        96\n"
     ]
    }
   ],
   "source": [
    "grid_search_clf = grid_search('recall_score')\n",
    "results = pd.DataFrame(grid_search_clf.cv_results_)\n",
    "results = results.sort_values(by='mean_test_recall_score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>mean_test_accuracy_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.957</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.999</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.958</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_precision_score  mean_test_recall_score  \\\n",
       "2                      0.957                   0.664   \n",
       "1                      0.950                   0.617   \n",
       "0                      0.958                   0.128   \n",
       "\n",
       "   mean_test_accuracy_score param_C param_kernel  \n",
       "2                     0.999      10          rbf  \n",
       "1                     0.999       1          rbf  \n",
       "0                     0.998     0.1          rbf  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[['mean_test_precision_score', 'mean_test_recall_score', 'mean_test_accuracy_score', 'param_C','param_kernel']].round(3).head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, probability=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(C=10,probability=True,kernel=\"rbf\")\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, probability=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(C=10,probability=True)\n",
    "svclassifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auprc: 0.7878267468248028\n",
      "sensitivity: 0.6530612244897959\n",
      "Accuracy: 0.9993445923013002\n",
      "[[85291     5]\n",
      " [   51    96]]\n"
     ]
    }
   ],
   "source": [
    "performance(svclassifier,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auprc: 0.7878267468248028\n",
      "sensitivity: 0.6530612244897959\n",
      "Accuracy: 0.9993445923013002\n",
      "[[85291     5]\n",
      " [   51    96]]\n"
     ]
    }
   ],
   "source": [
    "performance(svclassifier,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost-sensitive SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost_sensitive_SVM(weights,X,y):\n",
    "\n",
    "        accuracy=[]\n",
    "        sensitivity=[]\n",
    "        auprc=[]\n",
    "        for i in weights:\n",
    "            svclassifier = SVC(C=10,probability=True,kernel='rbf', class_weight=i)\n",
    "            svclassifier.fit(X_train, y_train)\n",
    "            y_pred = svclassifier.predict(X_test)\n",
    "            accuracy.append(metrics.accuracy_score(y_test, y_pred))\n",
    "            con=confusion_matrix(y_test, y_pred)\n",
    "            sensitivity.append(con[1][1]/(con[1][1]+con[1][0]))\n",
    "            y_prob=svclassifier.predict_proba(X_test)\n",
    "            auprc.append(metrics.average_precision_score(y_test,y_prob[:,1]))\n",
    "\n",
    "        result=pd.DataFrame({\"weights\":weights,\"accuracy\":accuracy,\"sensitivity\":sensitivity,\"auprc\":auprc})\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weights</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.746002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{0: 1, 1: 5}</td>\n",
       "      <td>0.999251</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.732220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{0: 1, 1: 30}</td>\n",
       "      <td>0.999087</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.696315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{0: 1, 1: 577}</td>\n",
       "      <td>0.999005</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.667252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          weights  accuracy  sensitivity     auprc\n",
       "0    {0: 1, 1: 3}  0.999274     0.666667  0.746002\n",
       "1    {0: 1, 1: 5}  0.999251     0.666667  0.732220\n",
       "2   {0: 1, 1: 30}  0.999087     0.673469  0.696315\n",
       "3  {0: 1, 1: 577}  0.999005     0.666667  0.667252"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights =[{0:1, 1:3},{0:1, 1:5}, {0:1, 1:30},{0:1, 1:577}]\n",
    "result=Cost_sensitive_SVM(weights,X_train,y_train)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight chosen: {1:3}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
